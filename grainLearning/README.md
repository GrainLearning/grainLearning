
# Welcome to GrainLearning!

|Author |Hongyang Cheng|
|--|--|
|Contacts |h.cheng@utwente.nl |
|Version|0.2 |

# Description

GrainLearning is a Python-based **Bayesian Calibration** tool for estimating parameter uncertainties in geomechanical models (currently only particle-scale and elastoplasticity models are tested). It uses the [recursive Bayes' rule](https://en.wikipedia.org/wiki/Recursive_Bayesian_estimation) to quantify the evolution of the probability distribution of parameters over time or a load history, and a **nonparametric Gaussian mixture** model to iteratively resample parameter space. The mixture model trained at the end of each iteration guides the resampling for the subsequent iteration towards global optima asymptotically, thus greatly reducing the computational cost, compared with [conventional approaches](https://en.wikipedia.org/wiki/Particle_filter). 

GrainLearning is developed to serve the ever-increasing need for fast and accurate estimation of particle- or microstructure-scale parameters in **discrete element method (DEM)** simulations of geomaterials. For that purpose, GrainLearning is implemented to work seamlessly with the open-source discrete numerical modeling framework **Yade**. However, integrating GrainLearning with other codes (e.g., [MercuryDPM](https://www.sciencedirect.com/science/article/pii/S0010465519304357), *not limited to DEM*) should be rather straight forward. One could either pass parameter samples generated by GrainLearning to (the executable of) your model from Python or implement your own [runModel](https://github.com/chyalexcheng/grainLearning/blob/master/grainLearning/YadeSim.py) module in Python.

# Documentation
## Introduction

## Bayesian inference

## Sequential Monte Carlo for Bayesian parameter estimation and UQ

## Iterative sampling using nonparametric Gaussian mixtures
 
# Code structure

To make the I/O easier, GrainLearning stores the reference/observation data as a dictionary*type variable. The user needs to provide the keys to the data sequence for the control and the output of a model evaluation. These two keys are passed to an SMC object and used to extract the corresponding dataset from the simulation data ([simData](https://github.com/chyalexcheng/grainLearning/blob/master/grainLearning/smc.py#L186)).
 
  # key for simulation control
  obsCtrl = 'u'
  # key for output data
  simDataKeys = ['f']

# Tutorials

The tutorials are currently provided with the goal to work with or post-process simulation data ([simData](https://github.com/chyalexcheng/grainLearning/blob/master/grainLearning/smc.py#L186)) from **Yade**. The model evaluations in this section are therefore the evaluations of a Yade model. In case of DEM modeling of granular soil, relevant parameters could be Young's modulus, friction coefficient, Poisson's ratio, rolling stiffness, and rolling friction, etc of a soil particle, as well as a structural parameter like a particle size distribution parameterized by its moments. In the following, we will walk you through the steps of Bayesian calibration using GrainLearning. The DEM model is simple enough such that the calibration should finish within a few minutes on a laptop.

## Two-particle collision in the normal direction

For the sake of brevity, we shall first use the simplest DEM simulation, i.e., two particles colliding in the normal direction, governed by the [Hertz-Mindlin contact law](https://yade-dem.org/doc/yade.wrapper.html?highlight=mindlin#yade.wrapper.Ip2_FrictMat_FrictMat_MindlinPhys). Assuming perfectly elastic collision, the number of parameters reduces to only two, namely, particle-scale Young's modulus $E$ and Poisson's ratio $\nu$ (weak dependency). In the following, we will demonstrate the capability of GrainLearning using such a simple DEM model. The tutorial [CaliCollision.py](https://github.com/chyalexcheng/grainLearning/blob/master/grainLearning/CaliCollision.py) is set up as follows.

 1. Create a synthetic dataset from the "two-particle" simulation (already in [GrainLearning/collision.dat](https://github.com/chyalexcheng/grainLearning/blob/master/grainLearning/collision.dat)) as the ground truth
>ObsData = np.loadtxt('collision.dat')
 2. Add Gaussian noise to the ground truth
>noise = np.random.normal(0, 0.1 * max(ObsData[1]), len(ObsData[1]))
 3. Run GrainLearning iteratively until the error is sufficiently small and see if the correct parameter values are recovered
>\# iterate the problem
> while smcTest.sigma > 1.0e-2 and iterNO < maxNumOfIters:
>&nbsp;&nbsp;&nbsp;&nbsp;\# initialize the weights
>&nbsp;&nbsp;&nbsp;&nbsp;smcTest.initialize(paramNames, paramRanges, numSamples, maxNumComponents, priorWeight, covType=covType, threads=threads)
>&nbsp;&nbsp;&nbsp;&nbsp;\# run sequential Monte Carlo
>&nbsp;&nbsp;&nbsp;&nbsp;ips, covs = smcTest.run(iterNO=iterNO, reverse=iterNO % 2)

### The driver script

To run the tutorial execute the driver script CaliCollision.py
> python CaliCollision.py

You will then be asked to give your initial guess of the upper limit of the normalized covariance $\sigma$. You could think of $\sigma$ as the error between the ground truth and your model evaluation which could be 100% or even larger. In fact, GrainLearning tries to find the $\sigma$ that results in an effective sample size equal to a user-specified value, via the root-finding algorithm of the scipy library.

  # user-defined parameter: upper limit of the normalized covariance coefficient
  sigma = float(input("Give an initial guess of the upper limit of normalized covariance: "))
  # target effective sample size specified by the user
  ess = 0.3
  obsWeights = [1.0]

Before entering the iteration loop of Bayesian filtering, provide the names of the unknown parameters and their upper and lower limits. They will be used only in the **first iteration** for generating uniform samples using the low-discrepancy sequence of [ghalton](https://ghalton.readthedocs.io/en/latest/).

  # give ranges of parameter values (E, \nu)
  paramNames = ['E', 'nu']
  numParams = len(paramNames)
  # use uniform sampling for the first iteration
  paramRanges = {'E': [10e9, 100e9], 'nu': [0.1, 0.5]}

For the **iterations afterward**, the parameter samples are drawn from the Gaussian mixture model that is trained at the end of the previous iteration. Although the Gaussian mixture model used here is nonparametric, it still requires hyper-parameters which are rough estimates of what the values of the actual parameters should be. The maximum number of Gaussians in a mixture model is a typical hyper-parameter. For the technical details on the maximum of Gaussian components and the prior weight (weight_concentration_prior), see the documentation of the [BayesianGaussinMixture](https://scikit-learn.org/stable/modules/generated/sklearn.mixture.BayesianGaussianMixture.html) class of scikit-learn.
  
  # set number of samples per iteration (e.g., num1D * N * logN for quasi-Sequential Monte Carlo)
  numSamples1D = 10  
  numSamples = int(numSamples1D * numParams * log(numParams))
  # set the maximum Gaussian components and prior weight
  maxNumComponents = int(numSamples / 10)
  priorWeight = 1. / maxNumComponents
  covType = 'tied'

GrainLearning offers the flexibility of being used in two different ways, either interactively with both GrainLearning and Yade running in Python or as a post-process tool to estimate parameter distribution using pre-run simData. The following sections will demonstrate two interactive modes and one stand-alone mode, respectively. Note that for evaluating models not written in Python, one could use the interactive mode with the model run outside Python or the stand-alone mode.

## Interactive modes

### Run model evaluations (DEM) within GrainLearning (Python)

The most efficient way of using GrainLearning is to wrap everything within a Python environment. This allows keeping the simulation data in the memory without the necessity of writing and reading them in text files, and thus less prone to error. To our knowledge, this is currently only possible with Yade. Furthermore, a unified Python environment also allows the possibility to synchronize GrainLearning and Yade in time, which means the user could pause the calibration at a certain time step, take a look at the probability distribution, and then decide whether proceed in time or jump to the resampling step because the statistics are already sufficient.

This interactive mode can be switched on simply by setting the variables `runYadeInGL=True` and `standAlone=False`. 

  # interactive mode with Yade running inside GrainLearning
  smcTest = smc(sigma, ess, obsWeights,
	  obsCtrl=obsCtrl, simDataKeys=simDataKeys, obsFileName='collisionObs.dat',
	  loadSamples=False, runYadeInGL=True, standAlone=False)

Some modification has to be made on the Yade script as well.
* Load Yade as a Python library
> 
  # yadeimport.py is generated by `ln yade-versionNo yadeimport.py`
  # add the directory where Yade is install
  sys.path.append(<directory where Yade is installed>)
  # import external dependencies
  from yadeimport import *
> See [https://yade-dem.org/doc/user.html?highlight=yadeimport#importing-yade-in-other-python-applications](https://yade-dem.org/doc/user.html?highlight=yadeimport#importing-yade-in-other-python-applications)
* Convert a Yade driver script (e.g., Collision.py) to functions ([YadeSim.py](https://github.com/chyalexcheng/grainLearning/blob/master/grainLearning/YadeSim.py)) that can be called from GrainLearning and managed by the multiprocessing module of Python

### Run model evaluations (DEM) outside GrainLearning (Python)

Perhaps, the easiest way to use GrainLearning and Yade together is to create a parameter table from GrainLearning and let Yade use it in batch mode, and then return to GrainLearning once the simulations are finished. This is essentially the stand-alone mode plus Python sending the Yade-batch jobs to the terminal.

To switch to this interactive mode, simply set `runYadeInGL=False` and `standAlone=False`. Of course, the user has to provide the Yade script which in our case is `yadeScript='Collision.py'`, the directory where the simulation data is stored `yadeDataDir='Collision'`, and the Yade command e.g., `yadeVersion='yade-batch'`. `simName` should also be provided to make the search for simulation data in `yadeDataDir` easier.

  # interactive mode with Yade running outside GrainLearning
  
  smcTest = smc(sigma, ess, obsWeights,
	  yadeVersion='yadedaily-batch', yadeScript='Collision.py', yadeDataDir='Collision',
	  obsCtrl=obsCtrl, simDataKeys=simDataKeys, simName='2particle', obsFileName='collisionObs.dat',
	  loadSamples=False, runYadeInGL=False, standAlone=False)

### Start iterative Bayesian calibration with a user-defined parameter table

The previous two sections assume that you have no prior knowledge of the probability distribution of the parameters and you would like to start from a state of ignornance, i.e., a uniform sampling. However, if you have some prior knowledge, you might want to start Bayesian calibration with your own parameter samples that are not uniform, either from another sampling algorithm or from the previous runs of GrainLearning. If this is desired, you simply need to specify the file name where your initial samples are stored when instantiating an smc object.


## Stand-alone mode

To make the 
# Installation

Follow the steps below to install GrainLearning on a Mac or Linux OS:

* Git and Python
> * brew install git python (Mac)
> * or sudo apt install git python (Linux)
* Python packages
> * sudo pip install numpy scipy matplotlib ghalton scikit-learn} 

* Clone the git repository
> * git clone https://github.com/chyalexcheng/grainLearning.git

* Optionally, we recommend you to use the Python IDE (e.g. PyCharm)

> * After installing PyCharm, open PyCharm, select Open Project, select the grainlearning directory. Then go to Preferences, search for Project Interpreter, select the Interpreter textbox, click Open All, click the + symbol to add a new interpreter, select your python executable, and importantly click Inherit global site packages (so you have packages like numpy available).

# Dependencies

# Referencing GrainLearning

If you are using this software in a work that will be published, please cite this paper:

H. Cheng, T. Shuku, K. Thoeni, Y. Yamamoto. **Probabilistic calibration of discrete element simulations using the sequential quasi-Monte Carlo filter.** _Granular Matter_ 20, 11 (2018). [10.1007/s10035-017-0781-y](https://doi.org/10.1007/s10035-017-0781-y)

H. Cheng, T. Shuku, K. Thoeni, P. Tempone, S. Luding, V. Magnanimo. **An iterative Bayesian filtering framework for fast and automated calibration of DEM models**. _Comput. Methods Appl. Mech. Eng.,_ 350 (2019), pp. 268-294, [10.1016/j.cma.2019.01.027](https://doi.org/10.1016/j.cma.2019.01.027)

# Help and Support

For assistance with the GrainLearning software or Bayesian calibration for geomechanical models in general, please raise an issue on the Github Issues page or drop me an email at h.cheng@utwente.nl.
